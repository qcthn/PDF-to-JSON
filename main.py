import streamlit as st
import pdfplumber
import pytesseract
from pdf2image import convert_from_path
from PIL import Image
import os
import shutil
import json
import pandas as pd
from docx import Document
import openai


# Ng∆∞·ªùi d√πng nh·∫≠p OpenAI API Key
api_key = st.text_input("üîë Nh·∫≠p OpenAI API Key:", type="password")
if not api_key:
    st.warning("Vui l√≤ng nh·∫≠p OpenAI API Key ƒë·ªÉ s·ª≠ d·ª•ng ·ª©ng d·ª•ng.")
    st.stop()

# C·∫•u h√¨nh OpenAI client
client = openai.OpenAI(api_key=api_key)

# Theo d√µi s·ªë request v√† chi ph√≠
total_requests = 0
total_cost = 0.0

# ƒê·ªãnh gi√° OpenAI API
PRICE_PER_1K_TOKENS = {
    "gpt-3.5-turbo": 0.002,  # $0.002 per 1K tokens
    "gpt-4-turbo": 0.01       # $0.01 per 1K tokens
}

def extract_text_from_pdf(pdf_path):
    """Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ file PDF."""
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
    except Exception as e:
        st.error(f"L·ªói khi x·ª≠ l√Ω PDF: {e}")
        return None
    return text

# Bi·∫øn theo d√µi s·ªë l·∫ßn request v√† chi ph√≠ s·ª≠ d·ª•ng OpenAI API
total_requests = 0
total_cost = 0.0

# ƒê·ªãnh gi√° OpenAI API (c√≥ th·ªÉ thay ƒë·ªïi n·∫øu OpenAI c·∫≠p nh·∫≠t gi√°)
PRICE_PER_1K_TOKENS = {
    "gpt-3.5-turbo": 0.0005,  # $0.002 per 1K tokens
    "gpt-4-turbo": 0.01       # $0.01 per 1K tokens
}
def clean_json_response(response_text):
    """L√†m s·∫°ch ph·∫£n h·ªìi GPT ƒë·ªÉ lo·∫°i b·ªè c√°c k√Ω t·ª± kh√¥ng mong mu·ªën tr∆∞·ªõc khi ph√¢n t√≠ch JSON."""
    response_text = response_text.strip()
    if response_text.startswith("```json"):
        response_text = response_text[7:]
    if response_text.endswith("```"):
        response_text = response_text[:-3]
    return response_text.strip()
# Bi·∫øn theo d√µi s·ªë l·∫ßn request v√† t·ªïng chi ph√≠ s·ª≠ d·ª•ng OpenAI API
total_requests = 0
total_cost = 0.0

# ƒê·ªãnh gi√° OpenAI API (c√≥ th·ªÉ thay ƒë·ªïi n·∫øu OpenAI c·∫≠p nh·∫≠t gi√°)
PRICE_PER_1K_TOKENS = {
    "gpt-3.5-turbo": 0.0005,  # $0.002 per 1K tokens
    "gpt-4-turbo": 0.01       # $0.01 per 1K tokens
}

def extract_info_with_gpt(text):
    """S·ª≠ d·ª•ng GPT-3.5 Turbo ƒë·ªÉ tr√≠ch xu·∫•t th√¥ng tin t·ª´ vƒÉn b·∫£n v√† t√≠nh to√°n chi ph√≠."""
    global total_requests, total_cost  # S·ª≠ d·ª•ng bi·∫øn to√†n c·ª•c ƒë·ªÉ theo d√µi s·ªë request v√† chi ph√≠

    prompt = f"""
    Tr√≠ch xu·∫•t th√¥ng tin sau t·ª´ vƒÉn b·∫£n CV v√† tr·∫£ v·ªÅ d∆∞·ªõi d·∫°ng JSON c√≥ c·∫•u tr√∫c h·ª£p l·ªá:
    {{
        "Name": "",
        "Email": "",
        "Phone": "",
        "Skills": [],
        "Experience": [],
        "Education": [],
        "Certifications": [],
        "Languages": []
    }}
    
    CV text:
    {text}
    """

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are an expert in extracting information from CVs (resume) and images with 10 years of experience in getting the exact information needed to recruit suitable positions for the company"
            "Context: I will provide you with resumes of candidates (can be 1 or more resumes) or image files containing text"
            "Your task is to extract information from the resumes and images I provide (I have taken the text from the resume and the image will be provided to you below) you return the output as a json file"
            "Some of the most important information required of each candidate: Name, Email, Phone number, Skills, Experience (including: position, timeline, responsibilities), Education (including: degree, institution, timeline, GPA), Certifications, Languages,... In addition, I can also provide you with documents related to identification and visa, you must also get important information in there."
            "Task: extract the following information from the CV text and return it as JSON"
            "output: json file format"
            "*** note here I can provide you with the text, but in that text will be a synthesis of many resumes of different candidates"
            "REMEMBER : the output only json format"},
            {"role": "user", "content": prompt}
        ]
    )

    # C·∫≠p nh·∫≠t s·ªë l·∫ßn request
    total_requests += 1

    # L·∫•y s·ªë token s·ª≠ d·ª•ng t·ª´ response
    if hasattr(response, "usage"):
        tokens_used = response.usage.total_tokens  # T·ªïng s·ªë token ti√™u t·ªën
        cost = (tokens_used / 1000) * PRICE_PER_1K_TOKENS["gpt-3.5-turbo"]  # Chi ph√≠ request
        total_cost += cost  # C·ªông d·ªìn v√†o t·ªïng chi ph√≠
    else:
        tokens_used = 0
        cost = 0.0

    # Tr√≠ch xu·∫•t n·ªôi dung ph·∫£n h·ªìi
    extracted_text = response.choices[0].message.content.strip()
    cleaned_text = clean_json_response(extracted_text)

    return json.loads(cleaned_text)

def display_summary():
    """Hi·ªÉn th·ªã t·ªïng s·ªë request v√† t·ªïng chi ph√≠ sau khi ho√†n t·∫•t."""
    st.write(f"üîÑ **T·ªïng s·ªë request API:** {total_requests}")
    st.write(f"üí∞ **T·ªïng chi ph√≠ OpenAI API:** ${total_cost:.4f}")


def save_to_json(data_list, output_path):
    """L∆∞u d·ªØ li·ªáu d∆∞·ªõi d·∫°ng JSON."""
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(data_list, f, ensure_ascii=False, indent=4)

def create_word_file(text_list, output_path):
    """T·∫°o file Word ch·ª©a n·ªôi dung tr√≠ch xu·∫•t."""
    try:
        doc = Document()
        for idx, (filename, text) in enumerate(text_list):
            doc.add_heading(f"File {idx + 1}: {filename}", level=1)
            doc.add_paragraph(text)
            doc.add_page_break()
        doc.save(output_path)
        return True
    except Exception as e:
        st.error(f"L·ªói khi t·∫°o file Word: {e}")
        return False

def main():
    st.title("üìÑ PDF to JSON Converter")
    st.write("üîπ T·∫£i l√™n t·ªëi ƒëa **200 file PDF**, tr√≠ch xu·∫•t vƒÉn b·∫£n, chuy·ªÉn ƒë·ªïi sang **Word & JSON**.")

    uploaded_files = st.file_uploader("üì§ Ch·ªçn file PDF", type=["pdf"], accept_multiple_files=True)
    temp_dir = "temp"
    os.makedirs(temp_dir, exist_ok=True)

    # Ch·ªâ hi·ªÉn th·ªã n√∫t khi c√≥ t·ªáp t·∫£i l√™n
    if uploaded_files:
        st.success(f"‚úÖ ƒê√£ t·∫£i l√™n {len(uploaded_files)} file PDF. Nh·∫•n **'B·∫Øt ƒë·∫ßu chuy·ªÉn ƒë·ªïi'** ƒë·ªÉ x·ª≠ l√Ω.")

        if st.button("üöÄ B·∫Øt ƒë·∫ßu chuy·ªÉn ƒë·ªïi PDF sang JSON"):
            with st.spinner("‚è≥ ƒêang x·ª≠ l√Ω... Vui l√≤ng ch·ªù gi√¢y l√°t."):
                extracted_data = []
                extracted_texts = []

                for uploaded_file in uploaded_files:
                    temp_file_path = os.path.join(temp_dir, uploaded_file.name)
                    with open(temp_file_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())

                    text = extract_text_from_pdf(temp_file_path)
                    if text:
                        extracted_texts.append((uploaded_file.name, text))
                        extracted_info = extract_info_with_gpt(text)
                        extracted_info["Filename"] = uploaded_file.name
                        extracted_data.append(extracted_info)
                    os.remove(temp_file_path)

                word_output = os.path.join(temp_dir, "extracted_texts.docx")
                if create_word_file(extracted_texts, word_output):
                    with open(word_output, "rb") as file:
                        st.download_button("üì• T·∫£i file Word", file, file_name="extracted_texts.docx")

                json_output = os.path.join(temp_dir, "extracted_data.json")
                save_to_json(extracted_data, json_output)
                with open(json_output, "rb") as file:
                    st.download_button("üì• T·∫£i file JSON", file, file_name="extracted_data.json")

            # Hi·ªÉn th·ªã s·ªë request & t·ªïng chi ph√≠ sau khi x·ª≠ l√Ω xong
            st.write(f"üîÑ T·ªïng s·ªë request API: **{total_requests}**")
            st.write(f"üí∞ T·ªïng chi ph√≠ OpenAI API: **${total_cost:.4f}**")

    shutil.rmtree(temp_dir, ignore_errors=True)

if __name__ == "__main__":
    main()
